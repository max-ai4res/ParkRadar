{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "d44TznbgZZgm",
    "outputId": "b722a31e-6c74-45d1-b07c-4bafb4c29a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "aFe4wHGRFKle",
    "outputId": "76e7edaa-60db-4cad-c567-277013795a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x296f061d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNh5NIckZZgu"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LMSg53fiZZgx",
    "outputId": "c3cdfb81-6db1-42c9-a93e-679e6d8ba933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data - 60000\n",
      "Number of test data - 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train data - \" + str(len(x_train)))\n",
    "print(\"Number of test data - \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFlNHktHBtru"
   },
   "source": [
    "## Split the data into train/validation/test data sets\n",
    "\n",
    "\n",
    "*   Training data - used for training the model\n",
    "*   Validation data - used for tuning the hyperparameters and evaluate the models\n",
    "*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "1ShU787gZZg0",
    "outputId": "2016e59c-a88b-4ecd-c9fa-1177011877d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "#(x_train, x_valid) = x_train, x_train[:5000] \n",
    "#(y_train, y_valid) = y_train, y_train[:5000]\n",
    "\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhalcO03ZZg3"
   },
   "source": [
    "## Create the model architecture\n",
    "\n",
    "There are two APIs for defining a model in Keras:\n",
    "1. [Sequential model API](https://keras.io/models/sequential/)\n",
    "2. [Functional API](https://keras.io/models/model/)\n",
    "\n",
    "In this notebook we are using the Sequential model API. \n",
    "If you are interested in a tutorial using the Functional API, checkout Sara Robinson's blog [Predicting the price of wine with the Keras Functional API and TensorFlow](https://medium.com/tensorflow/predicting-the-price-of-wine-with-the-keras-functional-api-and-tensorflow-a95d1c2c1b03).\n",
    "\n",
    "In defining the model we will be using some of these Keras APIs:\n",
    "*   Conv2D() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D/) - create a convolutional layer \n",
    "*   Pooling() [link text](https://keras.io/layers/pooling/) - create a pooling layer \n",
    "*   Dropout() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) - apply drop out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "colab_type": "code",
    "id": "QgTZ47SsZZg4",
    "outputId": "685749b8-c326-495a-c9c2-eb523173bd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               819456    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 896,522\n",
      "Trainable params: 896,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 18:49:21.816704: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-07 18:49:21.816853: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "my_augmenter = tf.keras.Sequential([\n",
    "    layers.RandomTranslation(0, 0.3, fill_mode='constant')\n",
    "])\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(layers.Input((28,28,1)))\n",
    "\n",
    "# model.add(layers.RandomTranslation(0, 0.3, fill_mode='constant')) # --- con KERAS 2.10.0 ha problemi!!\n",
    "###model.add(augmenter) #--> there is some problem with keras 2.10... so we need to skip this heare...\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='valid', activation='relu')) \n",
    "#model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "#model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.build(input_shape=(28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Augmenter\n",
    "There is a problem (apparently) in keras versio 2.10.0 that cause an improper behaviour of data augmentation if used direcly in the model... so instead of using augmenter into the processing layers of the model we apply a preprocessing layer for data augmentation...\n",
    "When keras problem is resolved is interesteing to retry the test making the augmenters part of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(tf.data.Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "def prepare_data(ds, shuffle=False, augmenter=None, batch_size=64, autotune=AUTOTUNE):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    if augmenter != None: \n",
    "        ds = ds.map(lambda x,y: (augmenter(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhxJ5dinZZg8"
   },
   "source": [
    "## Compile the model\n",
    "Configure the learning process with compile() API before training the model. It receives three arguments:\n",
    "\n",
    "*   An optimizer \n",
    "*   A loss function \n",
    "*   A list of metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQUlOa8cZZg9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtOvh3YVZZg_"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Now let's train the model with fit() API.\n",
    "\n",
    "We use  the [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x2944479d0>\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "train_ds = prepare_data(train_ds, shuffle=True)#, augmenter=my_augmenter)\n",
    "valid_ds = prepare_data(valid_ds, batch_size=64)\n",
    "\n",
    "print(my_augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m      3\u001b[0m datagen \u001b[39m=\u001b[39m ImageDataGenerator(rotation_range\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, width_shift_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,height_shift_range\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, horizontal_flip\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m datagen\u001b[39m.\u001b[39mfit(x_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=0, width_shift_range=0.2,height_shift_range=0, horizontal_flip=False)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "colab_type": "code",
    "id": "ZTmapAttZZhA",
    "outputId": "08770dfd-10f0-4fad-81a6-0b0333086281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "859/860 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.9616\n",
      "Epoch 1: val_loss improved from inf to 0.29351, saving model to xmodel.weights.best.hdf5\n",
      "860/860 [==============================] - 12s 14ms/step - loss: 0.1011 - accuracy: 0.9615 - val_loss: 0.2935 - val_accuracy: 0.9126\n",
      "Epoch 2/5\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9683\n",
      "Epoch 2: val_loss improved from 0.29351 to 0.28763, saving model to xmodel.weights.best.hdf5\n",
      "860/860 [==============================] - 13s 15ms/step - loss: 0.0836 - accuracy: 0.9683 - val_loss: 0.2876 - val_accuracy: 0.9160\n",
      "Epoch 3/5\n",
      "857/860 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9740\n",
      "Epoch 3: val_loss did not improve from 0.28763\n",
      "860/860 [==============================] - 12s 14ms/step - loss: 0.0697 - accuracy: 0.9741 - val_loss: 0.3062 - val_accuracy: 0.9182\n",
      "Epoch 4/5\n",
      "860/860 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9783\n",
      "Epoch 4: val_loss did not improve from 0.28763\n",
      "860/860 [==============================] - 12s 14ms/step - loss: 0.0587 - accuracy: 0.9783 - val_loss: 0.3276 - val_accuracy: 0.9134\n",
      "Epoch 5/5\n",
      "858/860 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9816\n",
      "Epoch 5: val_loss did not improve from 0.28763\n",
      "860/860 [==============================] - 12s 14ms/step - loss: 0.0489 - accuracy: 0.9816 - val_loss: 0.3641 - val_accuracy: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x30c7f5b70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer =  ModelCheckpoint(filepath='xmodel.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "\"\"\" model.fit(train_ds,\n",
    "         batch_size=64,\n",
    "         epochs=5,\n",
    "         validation_data=valid_ds,\n",
    "        callbacks=[checkpointer]) \"\"\"\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-MGLwZQy05d"
   },
   "source": [
    "## Load Model with the best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "print(h5py.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD1tecxUZZhE"
   },
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RTRkan4yq5H"
   },
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VZtqBqFFy62R",
    "outputId": "7cc9a4dd-1641-4a94-f4ce-c209cf9a142d"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJv7XEk10bOv"
   },
   "source": [
    "## Visualize prediction\n",
    "Now let's visualize the prediction using the model you just trained. \n",
    "First we get the predictions with the model from the test data.\n",
    "Then we print out 15 images from the test data set, and set the titles with the prediction (and the groud truth label).\n",
    "If the prediction matches the true label, the title will be green; otherwise it's displayed in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "QwNmlfIC0YxM",
    "outputId": "dc74804f-8871-43a6-ea37-3ef4d57d413f"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "\n",
    "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(x_test[index]))\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(y_test[index])\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
    "                                  fashion_mnist_labels[true_index]),\n",
    "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "ix = 24300\n",
    "test_img = np.array(x_train[ix].reshape(1,28,28,1))\n",
    "model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for px in range(-5,6):\n",
    "    img = test_img\n",
    "    img = img.reshape(28,28)\n",
    "    img = np.roll(img, px, axis=1)\n",
    "    #img_data = torch.tensor(img).view(-1,1,28,28).to(device)\n",
    "    #np_out = model(img_data).cpu().detach().numpy()\n",
    "    pred = model.predict(img.reshape(1,28,28,1))\n",
    "    preds.append(pred)\n",
    "    plt.imshow(img)\n",
    "    plt.title(fashion_mnist_labels[pred[0].argmax()])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,10))\n",
    "plt.title('Probability of each class for various translations')\n",
    "sns.heatmap(np.array(preds).reshape(11,10), \n",
    "            annot=True, ax=ax, fmt='.2f', \n",
    "            xticklabels=fashion_mnist_labels, \n",
    "            yticklabels=[str(i)+str(' pixels') for i in range(-5,6)], \n",
    "            cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fashion_mnist_keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "674139ce970fa82af6c6fe3ae01acbbd310fc9bc5f2c77f577d46474d716e82a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
